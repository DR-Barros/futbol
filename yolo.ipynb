{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88f35792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
      "View Ultralytics Settings with 'yolo settings' or at '/home/dani/.config/Ultralytics/settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6.25M/6.25M [00:01<00:00, 5.57MB/s]\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "\n",
    "# Cargar el modelo preentrenado (por ejemplo, YOLOv8n, YOLOv8s, etc.)\n",
    "model = YOLO(\"yolov8n.pt\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0c1bcbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/dani/Desktop/futbol/example.jpg: 416x640 5 persons, 30.6ms\n",
      "Speed: 2.7ms preprocess, 30.6ms inference, 79.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "[ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: None\n",
      "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
      "obb: None\n",
      "orig_img: array([[[  8,   9,   7],\n",
      "        [  8,   9,   7],\n",
      "        [  7,   8,   6],\n",
      "        ...,\n",
      "        [ 22,  21,  30],\n",
      "        [ 22,  21,  30],\n",
      "        [ 22,  21,  30]],\n",
      "\n",
      "       [[  8,   9,   7],\n",
      "        [  8,   9,   7],\n",
      "        [  8,   9,   7],\n",
      "        ...,\n",
      "        [ 21,  20,  29],\n",
      "        [ 21,  20,  29],\n",
      "        [ 21,  20,  29]],\n",
      "\n",
      "       [[  9,  10,   8],\n",
      "        [  8,   9,   7],\n",
      "        [  8,   9,   7],\n",
      "        ...,\n",
      "        [ 16,  15,  24],\n",
      "        [ 16,  15,  24],\n",
      "        [ 16,  15,  24]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 53, 180, 128],\n",
      "        [ 46, 176, 121],\n",
      "        [ 44, 171, 119],\n",
      "        ...,\n",
      "        [ 52, 172, 118],\n",
      "        [ 61, 181, 127],\n",
      "        [ 68, 188, 134]],\n",
      "\n",
      "       [[ 39, 169, 114],\n",
      "        [ 33, 166, 109],\n",
      "        [ 32, 162, 107],\n",
      "        ...,\n",
      "        [ 41, 161, 107],\n",
      "        [ 48, 168, 114],\n",
      "        [ 54, 174, 120]],\n",
      "\n",
      "       [[ 36, 169, 112],\n",
      "        [ 32, 165, 108],\n",
      "        [ 30, 163, 106],\n",
      "        ...,\n",
      "        [ 53, 173, 119],\n",
      "        [ 48, 168, 114],\n",
      "        [ 44, 164, 110]]], shape=(392, 612, 3), dtype=uint8)\n",
      "orig_shape: (392, 612)\n",
      "path: '/home/dani/Desktop/futbol/example.jpg'\n",
      "probs: None\n",
      "save_dir: '/home/dani/Desktop/futbol/runs/detect/predict'\n",
      "speed: {'preprocess': 2.663182000105735, 'inference': 30.577698998968117, 'postprocess': 79.915311998775}]\n"
     ]
    }
   ],
   "source": [
    "# Cargar imagen\n",
    "image_path = \"example.jpg\"\n",
    "results = model(image_path)\n",
    "print(results)  # Imprimir resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db42c984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persona detectada en: (112.66673278808594, 18.499736785888672), (423.9985656738281, 377.3861083984375)\n",
      "Persona detectada en: (34.229591369628906, 84.89447021484375), (108.04861450195312, 295.09075927734375)\n",
      "Persona detectada en: (537.9708251953125, 125.15662384033203), (592.1982421875, 233.28688049316406)\n",
      "Persona detectada en: (371.10302734375, 67.37295532226562), (427.9504089355469, 314.15460205078125)\n",
      "Persona detectada en: (117.51016998291016, 122.64320373535156), (219.3135528564453, 310.6005554199219)\n"
     ]
    }
   ],
   "source": [
    "# Filtrar personas y mostrar resultados\n",
    "for result in results:\n",
    "    boxes = result.boxes\n",
    "    for box in boxes:\n",
    "        cls_id = int(box.cls[0])  # Clase detectada\n",
    "        if model.names[cls_id] == 'person':\n",
    "            x1, y1, x2, y2 = box.xyxy[0].tolist()  # Coordenadas de la caja\n",
    "            print(f\"Persona detectada en: ({x1}, {y1}), ({x2}, {y2})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae7f1190",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Mostrar la imagen con las detecciones\n",
    "results[0].plot()  # Dibuja las cajas\n",
    "cv2.imshow(\"Detecciones\", results[0].plot())\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174808bd",
   "metadata": {},
   "source": [
    "# Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "60bb86b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU disponible: True\n",
      "Usando: NVIDIA GeForce RTX 4060\n",
      "Modelo cargado en: cuda:0\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "print(\"GPU disponible:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Usando:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "model.to('cuda')  \n",
    "model.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Modelo cargado en:\", model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba6709f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[45]\u001b[39m\u001b[32m, line 39\u001b[39m\n\u001b[32m     37\u001b[39m gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n\u001b[32m     38\u001b[39m gray_blur = cv2.medianBlur(gray, \u001b[32m5\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m circles = \u001b[43mcv2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mHoughCircles\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgray_blur\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mHOUGH_GRADIENT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdp\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mminDist\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam1\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam2\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mminRadius\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxRadius\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m lines \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     41\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(\"SoccerNet/england_epl/2014-2015/2015-02-21 - 18-00 Chelsea 1 - 1 Burnley/1_720p.mkv\")\n",
    "\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"No se pudo abrir el video.\")\n",
    "    exit()\n",
    "# Rango para el color blanco\n",
    "lower_white = np.array([30, 10, 210])\n",
    "upper_white = np.array([110, 70, 255])\n",
    "prev_frame = None\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    results = model.predict(frame, device='cuda' if torch.cuda.is_available() else 'cpu', verbose=False)\n",
    "    annotated_frame = frame.copy()\n",
    "    for result in results:\n",
    "        boxes = result.boxes\n",
    "        for box in boxes:\n",
    "            cls_id = int(box.cls[0])  # Clase detectada\n",
    "            if model.names[cls_id] == 'person':\n",
    "                x1, y1, x2, y2 = box.xyxy[0].tolist()  # Coordenadas de la caja\n",
    "                #nos quedamos con los enteros\n",
    "                x1, y1, x2, y2 = map(int, (x1, y1, x2, y2))\n",
    "                cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                \n",
    "    #convertimos a HSV\n",
    "    hsv_frame = cv2.cvtColor(annotated_frame, cv2.COLOR_BGR2HSV)\n",
    "    # Crear una máscara para el color blanco\n",
    "    mask = cv2.inRange(hsv_frame, lower_white, upper_white)\n",
    "    # Aplicar la máscara a la imagen original\n",
    "    masked_frame = cv2.bitwise_and(annotated_frame, annotated_frame, mask=mask)\n",
    "    # Aplicar detección de bordes\n",
    "    edges = cv2.Canny(masked_frame, 50, 150)\n",
    "    # Detección de líneas\n",
    "    lines = cv2.HoughLinesP(edges, 1, np.pi / 180, threshold=50, minLineLength=100, maxLineGap=10)\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            x1, y1, x2, y2 = line[0]\n",
    "            cv2.line(annotated_frame, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "    #Mostrar mascara\n",
    "    cv2.imshow(\"Mascara\", masked_frame)\n",
    "    cv2.imshow(\"Bordes del Video\", edges)\n",
    "    # Mostrar la imagen con las detecciones\n",
    "    cv2.imshow(\"Detecciones\", annotated_frame)\n",
    "    # Esperar hasta que se presione una tecla\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
